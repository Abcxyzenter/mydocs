---
layout: post
title:  "Юникод"
date:   2019-08-28 11:25:04 +0300
categories: unicode
---

Изначально все компьютеры использовали только символы английского алфавита, которые умещались в 127 кодовых точек ( 0-31 - непечатные, или управляющие символы, 32-127 - печатные. ), поэтому в большинстве случаев все обходились одной кодировкой - ASCII. 

Для локализации программного обеспечения, а также при создании специфических продуктов создавались альтернативные кодировки, поддерживающие конкретный язык. Символы для локализаций обычно располагались в следующих за стандартными английскими кодовыми точками - в диапазоне 128-255, таким образом в разных кодировках на одном и том же «адресе» могли располагаться совершенно разные знаки.

А затем появились электронная почта, мессенджеры и абракадабра на экранах компьютеров, пытавшихся отобразить иностранный контент.


## Что такое Unicode

Unicode - это стандарт, призванный унифицировать отображение текста и знаков на всех устройствах вне зависимости от основного используемого программным обеспечением  набора символов. 

Кодировки, соответствующие стандарту юникод имеют четко заданные «координаты» (кодовые точки) для каждого зарегистрированного символа, что сильно упрощает поддержку многоязычности в приложениях.

Для удобства мы можем представить кодировки стандарта юникод в виде массива, где кодовые точки это ключи, а байты символов - значения.
В стандарте предусмотрена запись в виде U+244E, которая соответствует кодовой точке (условно -  «ключу» в массиве) 0x244e. 

Полная таблица символов юникода содержит в себе большинство существующих и мертвых языков планеты, а также общепринятные символы и эмодзи.

Однажды получив индекс в таблице символов юникода символ остается на этом месте навсегда, поэтому разработчикам можно не беспокоиться о том, что стандарт может поменяться (он только дополняется новыми символами, добавляемыми на незанятые индексы: на данный момент используется приблизительно 110 000 кодовых точек). 

Наиболее распространенными кодировками, соответствующими стандарту Юникод являются UTF-8 и UTF-16. 


## Особенности Unicode-кодировок

В отличие от ASCII и ANSI (и доступных 255 кодовых точек) таблица символов Юникода рассчитана на 1 114 112 (из них доступны 1 111 998) кодовых точек, причем первые 127 из них полностью совпадают с ASCII кодировкой (в случае UTF-8 эти символы также совпадают с ASCII по размерам, что обеспечивает обратныю совместимость).

Символы юникода кодируются либо отдельно, либо, в случае образования сложных символов (например, иероглифы), могут образовывать суррогатные пары (комбинации из нескольких символов) и если символы ASCII занимают строго по 1 байту, то символы юникода могут "весить" до 4 байт (UTF-8 - от 1 до 4 байт на символ, UTF-16 - от 2 до 4 байт на символ).

Юникод поддерживает письменности слева направо, справа налево, в также двунаправленные (например, иероглифы).

В UTF-16 выделяют два вида последовательностей: little endian (процессоры x86, обратный порядок младших и старших байт) и big endian (процессоры m86k и SPARK). 
Например:
```
//Cимвол, представленный big endian 
 d8 89 dc 3f
//В little endian будет закодирован как 
 89 d8 3f dc 
```

По скольку в UTF-16 количество байт на символ может меняться, для избежания некорректной интерпретации старших и младших байтов было введено соглашение о метке порядка. Для обозначения little endian в начале строки устанавливается U+FFFE, в big-endian U+FEFF. Также для обозначения кодировок little-endian / big-endian можно заранее объявить тип кодировки: UTF-16LE / UTF-16BE.


## Отличия UTF-8 и UTF-16

Основное отличие UTF-8 от UTF-16 - количество байтов, используемое для кодирования символов: собственно, 8 и 16 в названии кодировок - это битовый размер комбинации указателей кодовых точек (представление единицы закодированного текста). В UTF-8 кодовая точка будет представлена в виде четырех кодовых единиц, а в UTF-16 - в виде двух, что непосредственно влияет на итоговый размер файла. 
Наиболее яркий пример - использование только ASCII символов: такой файл, закодированный в UTF-8 будет в два раза меньше файла UTF-16. С точки зрения размера, дополнительным преимуществом UTF-8 является тот факт, что большинство форматированных текстовых форматов уже имеют символы ASCII для форматирования - за счет этого при использовании UTF-8 их размер значитально снижается.

UTF-8 обратно совместим с ASCII, так как первые 127 символов идентичны последней поэтому можно сказать, что текст, написанный только с использованием первых 127 символов UTF-8 одновременно является и ASCII текстом. И, напротив, из-за разницы в размерах (2 байта у UTF-16) первых 127 символов старые программы просто не смогут открыть файлы, закодированные в UTF-16. Таким образом чтобы адаптировать старую программу для работы с UTF-16 потребуется переписать весь код, связанный с работой с текстом.

Для работы с байт-ориентированными сетями для UTF-16 нужно устанавливать порядок байтов, для UTF-8 этого делать не нужно, так как это байт-ориентированный формат. Более того, UTF-8 является единственной кодировкой для XML, не требующей наличия маркера последовательности байтов.

UTF-8 легко распознается эвристическими алгоритмами, благодаря чему даже в тех случаях, когда UTF-8 смешался с другими кодировками - велика вероятность его распознавания, и, кроме того, даже в случаях потери некоторых байтов можно легко определить границы символов, после чего восстановить поврежденный текст.

В начале строк UTF-8 отсутствует U+FFFE или U+FEFF, соответственно при передаче данных по FTP протоколам, либо через Telnet нет необходимости удалять эти символы. 

UTF-16 менее активно применяется и может быть актуален лишь в случаях, когда в качестве основного языка используется язык с большим количеством не ASCII символов (например, иероглифы и эмодзи) - на такие символы UTF-8 может брать в среднем 3 байта на символ против двух байтов для UTF-16.
 
 
## Некоторые особенности использования юникода в языках программирования

В Qt, Java и C#, python 3 для внутреннего представления строк используется UTF-16, однако, стоит отметить, что строки в данном случае понимаются как массив символов, а не массив байт. 
Рассмотрим более подробно на примере python 3 и C:


### Python 3

В третьей версии python появилась поддержка unicode. 
Для записи в кодировке этого стандарта используется тип str.
Методы encode() и decode() позволяет кодировать и декодировать str в/из bytes, принимая в качестве аргумента название кодировки, например 
```
myString.encode(“utf-8”)
```
Все символы-литералы допустимо использовать в качестве идентификатора.
Стоит обратить внимание на метод len() - в случае str - длина символа будет равна 1, однако, если строка юникода записана в bytes - длина символа зависит от его длины в кодировке и может быть в диапазоне от 1 до 4.
Символы перевода каретки и возврата строки кодируются также в юникоде.
Стоит отметить, что кодировка, установленная по умолчанию в open() может отличаться в зависимости от настроек, поэтому данный момент стоит проверять:
```
locale.getpreferredencoding()
```
Существует также весьма удобный модуль unicodedata, который позволяет искать символы в базе данных юникода, например:
```
import unicodedata

#поиск по символу
unicodedata.name("€") 

#поиск по названию
unicodedata.lookup("EURO SIGN")
```


### С

Стандартные символьные данные (ANSI) используют тип char, занимающий в памяти один байт. 

В UNIX по умолчанию узкие строки (char) считывают UTF-8 и, если они совпадают с ASCII - то символы корректно воспринимаются. 

Для символов UTF-16 используется двухбайтный тип данных - wchar_t. Важный момент: строки в случае с юникодом являются массивами символов ( а не байтами или char’ами), соответственно, к примеру для выделения памяти, размер массива нужно считать:
```
malloc(wCharString *sizeof(TCHAR))
```
При разработке под windows семейства NT рекомендуется использование макрокоманд: 
```
typedef wchar_t WCHAR;
```
В более поздних версиях:
```
typedef unsigned short wchar_t
```
Константы указываются с префиксом L
```
WCHAR symbol = L’s’;
WCHAR str[] = L’string’;
```
В случае, если нужно унифицировать запись типов данных:
```
#define UNICODE

#ifdef UNICODE
typedef wchar_t WCHAR;
typedef WCHAR TCHAR; 
#endif

TCHAR charSymbol = TEXT(‘a’);
TCHAR charString = TEXT(‘str’);
```

Если UNICODE не будет определен в начале файла ( #define UNICODE ) - TCHAR и TEXT будут преобразованы в char.

Для обозначения завершения строки используется 16 разрядный нуль: TEXT(‘\0’);
Возврат каретки (CR) 0x000D, перевод строки (LF) 0x000A, разделение строк 0x2028, абзац 0x2029.

0xFEFF и FFEF - начало новой строки (обязательно к использованию)

Еще полезные функции:

GetTextCharset - идентификатор набора юникода.
GettextCharsetInfo - подробная информация о шрифте.
mbstowcs (а также в windows MultiByteToWideChar) - преобразование строк однобайтовых символов в строку юникода.
wcstombs (а также в windows WideCharToMultiByte) - преобразование строк символов юникода в однобайтовые строки (в случаях если это возможно).

В Windows рекомендуется использовать MultiByteToWideChar и WideCharToMultiByte, т.к. эти функции принимают в качестве аргументов номера кодовых страниц для набора символов (то есть можно указать напрямую, где искать нужные кодовые точки), а также могут, в зависимости от флагов по-разному обрабатывать надстрочные/подстрочные знаки, а также неправильные символы.

В Windows-приложениях для выбора шрифта применяется функция ChooseFont. Набор символов задается в поле IfCharSet структуры LOGFONT. В случае с кириллицей мы имеем такие наборы как ANSI_CHARSET, OEM_ CHARSET, RUSSIAN_CHARSET и DEFAULT_CHARSET. Соответственно, чтобы работать с кириллическим юникодом нужно выбирать RUSSIAN_CHARSET.

Для работы с юникод строками существуют функции, аналогичные тем строковым функциям, которые используются при работе с ANSI:

```
char *strcat(char *, const char *);
wchar_t * wcscat(wchar_t*, const wchar t *);

char *strchr(const char*, int);
wchar_t * wcschr(const wchar_t *,wchar_t);

int strcmp(const char *, const char *);
int wcscmp(const wchar_t*, const wchar_t *);

char *strcpy(char *, const char *);
wchar_t * wcscpy(wchar_t*, const wchar_t *);

size_t strlen(const char *);
size_t wcslen(const wchar_t*);
```

Для удобства можно просто заменить str на wcs в начале названий вызываемых функций.

Указатели:
PWSTR - указатель на строку
PCWSTR - указатель на строковую константу

В WinAPI также присутствуют различия:
```
HWND WINAPI CreateWindowExW 	
```

вместо	  
```
HWND WINAPI CreatcWindowExA
```
Унифицированный вариант:
```
#ifdef UNICODE

#define CreateWindowEx CreateWindowExW #else

#define CreateWindowEx CreateWindowExA #endif

Для открытия текстовых файлов используйте функцию IsTextUnicode;

```
