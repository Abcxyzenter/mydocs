
Кодировка - метод хранения в памяти ПК печатных символов. Изначально все компьютеры использовали только символы английского алфавита, которые умещались в 127 кодовых точек ( 0-31 - непечатные - или управляющие - символы, 32 -127 - печатные. ), поэтому в большинстве случаев все обходились одной кодировкой - ASCII. 
Для локализации программного обеспечения, а также при создании специфических продуктов (например компьютеры IBM) как правило создавались альтернативные кодировки, поддерживающие конкретный язык. Символы для локализаций как правило располагались в следующих за стандартными английскими кодовыми точками - в диапазоне 128-255, таким образом в разных кодировках на одном и том же «адресе» могли располагаться совершенно разные знаки.
А затем появились интернет, электронная почта и абракадабра на экранах компьютеров, пытавшихся отобразить иностранный контент.

##Что такое Unicode

Unicode - это стандарт, призванный унифицировать отображение текста и знаков на всех устройствах вне зависимости от основного используемого программным обеспечением  набора символов. Кодировки, соответствующие стандарту юникод имеют четко заданные «координаты» (кодовые точки) для каждого зарегистрированного стандартом символа, что сильно упрощает поддержку многоязычности в приложениях.

Для удобства мы можем представить кодировки стандарта юникод в виде массива, где кодовые точки это ключи, а байты символов - значения.
В стандарте предусмотрена запись в виде U+244E что соответствует кодовой точке (условно -  «ключу») 0x244e. 

Однажды получив индекс в таблице символов юникода символ остается на этом месте навсегда, благодаря чему можно не беспокоиться о том, что стандарт может поменяться (он только дополняется новыми символами, добавляемыми на незанятые индексы - на данный момент используется приблизительно 110000 кодовых точек ). Полная таблица символов юникода содержит в себе большинство существующих и мертвых языков планеты, а также общепринятные символы и эмодзи.

В случае если в на компьютере отсутствует тот или иной символ - он будет заменен на знак вопроса, например L?wenbrau, m?t?rhead.

В отличие от ASCII (и 255 кодовых точек) таблица символов Юникода рассчитана на 1 114 112 (из них 1 111 998 доступны) кодовых точек. Первые 127 из которых полностью совпадают с ASCII кодировкой (в случае UTF-8 эти символы также совпадают с ASCII по размерам, что обеспечивает обратныю совместимость).

Наиболее распространенными кодировками, соответствующими стандарту Юникод являются UTF-8 (используется чаще всего) и UTF-16. 

##Особенности Unicode-кодировок

Символы юникод кодировок кодируются либо отдельно, либо, в случае образования сложных символов (например, иероглифы) могут образовывать суррогатные пары (комбинации из нескольких символов в одной точке).

Юникод поддерживает письменности слева направо, справа налево, в также двунаправленные (например, иероглифы).

Кодировка UTF-8 занимает от 1 до 4 байт на символ, кодировка UTF-16 - от 2 до 4 байт на символ.

По скольку в UTF-16 количество байт на символ может меняться - для избежания некорректной интерпретации старших и младших байтов было введено соглашение о метке порядка байтов - для этого в начале новой строки Юникода добавляется U+FFFE либо U+FEFF.

Символы UTF-16 представлены последовательносьтю двух или четырех байтов. Выделяют два вида последовательностей: little endian (процессоры x86, обратный порядок младших и старших байт) и big endian (процессоры m86k и SPARK). 

Например, символ, представленный big endian как d8 89 dc 3f, в little endian будет закодирован как 89 d8 3f dc

Для обозначения little endian в начале строки  вместо U+FEFF устанавливается U+FFFE. Также для обозначения кодировок little-endian / big-endian можно заранее объявить тип кодировки: UTF-16LE / UTF-16BE.


##Отличия UTF-8 и UTF-16

Собственно, 8 и 16 в названии - это битовый размер комбинации бит-указателей (представление единицы закодированного текста, кодовой точки) в UTF-8 и UTF-16. В UTF-8 кодовая точка будет представлена в виде четырех кодовых единиц, а в UTF-16 - в виде двух.

Основное отличие UTF-8 от UTF-16 - количество байтов, используемое для кодирования символов, что влияет на размер конечного файла. Наиболее показательный пример - использование только ASCII символов: такой файл, закодированный в UTF-8 будет в два раза меньше файла UTF-16. Стоит отметить, что большинство форматированных текстовых форматов уже имеют символы ASCII для форматирования - засчет этого при использовании UTF-8 их размер значитально снижается.

UTF-8 обратно совместим с ASCII, так как первые 127 символов идентичны последней (включая размер символа в 1 байт). Можно даже сказать, что текст, написанный только с использованием первых 127 символов юникода одновременно является и ASCII текстом. И, напротив, из-за разницы в размерах первых 127 символов старые программы просто не смогут открыть файлы, закодированные в UTF-16. Таким образом чтобы адаптировать старую программу для работы с UTF-16 потребуется переписать весь код, связанный с работой с текстом.

Для работы с байт-ориентированными сетями для UTF-16 нужно устанавливать порядок байтов, для UTF-8 этого делать не нужно, так как это байт-ориентированный формат. Более того, UTF-8 является единственной кодировкой для XML, не требующей наличия маркера последовательности байтов.

UTF-8 легко распознается эвристическими алгоритмами, благодаря чему даже в тех случаях, когда UTF-8 смешался с другими кодировками - велика вероятность его распознавания.

В начале строк UTF-8 отсутствует U+FFFE или U+FEFF, соответственно при передаче данных по FTP протоколам, либо через Telnet нет необходимости удалять эти символы. 

UTF-8 - самосинхронизирующаяся (легко определяются границы символов, даже в случаях потери некоторых байтов) и наиболее популярная на данный момент кодировка.

С другой стороны, в случаях, когда в качестве основного языка файлов является язык с большим количеством не ASCII символов и символов из диапазона 128-155 для уменьшения размера файла UTF-16 предпочтительнее, так как в этом случае кодировка UTF-8 будет брать в среднем 3 байта на символ против двух байтов для UTF-16.
 
##Некоторые особенности использования юникода в языках программирования

В Qt, Java и C#, python 3 для внутреннего представления строк используется UTF-16, однако, стоит отметить, что строки в данном случае понимаются как массив символов, а не массив байт. 
Рассмотрим более подробно на примере python 3 и C:

###Python 3

В третьей версии python появилась поддержка unicode. 
Для записи в кодировке этого стандарта используется тип str.
Методы encode() и decode() позволяет кодировать и декодировать str в/из bytes, принимая в качестве аргумента название кодировки, например 

myString.encode(“utf-8”)

Все символы-литералы допустимо использовать в качестве идентификатора.
Стоит обратить внимание на метод len() - в случае str - длина символа будет равна 1, однако, если строка юникода записана в bytes - длина символа зависит от его длины в кодировке и может быть в диапазоне от 1 до 4.
Символы перевода каретки и возврата строки кодируются также в юникоде.
Стоит отметить, что кодировка, установленная по умолчанию в open() может отличаться в зависимости от настроек, поэтому данный момент стоит проверять:

locale.getpreferredencoding()

Существует также весьма удобный модуль unicodedata, который позволяет искать символы в базе данных юникода, например:
```
import unicodedata

#поиск по символу
unicodedata.name("€") 

#поиск по названию
unicodedata.lookup("EURO SIGN")
```

###С

Стандартные символьные данные (ANSI) используют тип char, занимающий в памяти один байт. 

В UNIX по умолчанию узкие строки (char) считывают UTF-8 и, если они совпадают с ASCII - то символы корректно воспринимаются. 

Для символов UTF-16 используется двухбайтный тип данных - wchar_t. Важный момент: строки в случае с юникодом являются массивами символов ( а не байтами или char’ами), соответственно, к примеру для выделения памяти, размер массива нужно считать:
```
malloc(wCharString *sizeof(TCHAR))
```
При разработке под windows семейства NT рекомендуется использование макрокоманд: 

typedef wchar_t WCHAR;

В более поздних версиях:
typedef unsigned short wchar_t

Константы указываются с префиксом L

WCHAR symbol = L’s’;
WCHAR str[] = L’string’;

В случае, если нужно унифицировать запись типов данных:
```
#define UNICODE

#ifdef UNICODE
typedef wchar_t WCHAR;
typedef WCHAR TCHAR; 
#endif

TCHAR charSymbol = TEXT(‘a’);
TCHAR charString = TEXT(‘str’);
```

Если UNICODE не будет определен в начале файла ( #define UNICODE ) - TCHAR и TEXT будут преобразованы в char.

Для обозначения завершения строки используется 16 разрядный нуль: TEXT(‘\0’);
Возврат каретки (CR) 0x000D, перевод строки (LF) 0x000A, разделение строк 0x2028, абзац 0x2029.

0xFEFF и FFEF - начало новой строки (обязательно к использованию)

Еще полезные функции:

GetTextCharset - идентификатор набора юникода.
GettextCharsetInfo - подробная информация о шрифте.
mbstowcs (а также в windows MultiByteToWideChar) - преобразование строк однобайтовых символов в строку юникода.
wcstombs (а также в windows WideCharToMultiByte) - преобразование строк символов юникода в однобайтовые строки (в случаях если это возможно).

В Windows рекомендуется использовать MultiByteToWideChar и WideCharToMultiByte, т.к. эти функции принимают в качестве аргументов номера кодовых страниц для набора символов (то есть можно указать напрямую, где искать нужные кодовые точки), а также могут, в зависимости от флагов по-разному обрабатывать надстрочные/подстрочные знаки, а также неправильные символы.

В Windows-приложениях для выбора шрифта применяется функция ChooseFont. Набор символов задается в поле IfCharSet структуры LOGFONT. В случае с кириллицей мы имеем такие наборы как ANSI_CHARSET, OEM_ CHARSET, RUSSIAN_CHARSET и DEFAULT_CHARSET. Соответственно, чтобы работать с кириллическим юникодом нужно выбирать RUSSIAN_CHARSET.

Для работы с юникод строками существуют функции, аналогичные тем строковым функциям, которые используются при работе с ANSI:

```
char *strcat(char *, const char *);
wchar_t * wcscat(wchar_t*, const wchar t *);

char *strchr(const char*, int);
wchar_t * wcschr(const wchar_t *,wchar_t);

int strcmp(const char *, const char *);
int wcscmp(const wchar_t*, const wchar_t *);

char *strcpy(char *, const char *);
wchar_t * wcscpy(wchar_t*, const wchar_t *);

size_t strlen(const char *);
size_t wcslen(const wchar_t*);
```

Для удобства можно просто заменить str на wcs в начале названий вызываемых функций.

Указатели:
PWSTR - указатель на строку
PCWSTR - указатель на строковую константу

В WinAPI также присутствуют различия:
```
HWND WINAPI CreateWindowExW 	
```

вместо	  
```
HWND WINAPI CreatcWindowExA
```
Унифицированный вариант:
```
#ifdef UNICODE

#define CreateWindowEx CreateWindowExW #else

#define CreateWindowEx CreateWindowExA #endif

Для открытия текстовых файлов используйте функцию IsTextUnicode;

```
